{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9iaGB-cXLZ6x",
    "outputId": "f36fef8c-24f2-4607-f549-c1f188160757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Oci0gcXRGlQ",
    "outputId": "ad381ea5-e9b4-4523-b21e-8bff09582934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
      "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ibZ0RGHWL5v_"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K0_lxlNwL_aV"
   },
   "outputs": [],
   "source": [
    "# Створення Spark-сесії\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data Processing with Spark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "nuek_vuh3_data_path = '/content/drive/MyDrive/GoIT/DataEngineering/lesson4/nuek-vuh3.csv'\n",
    "\n",
    "# Завантаження даних\n",
    "nuek_vuh3_df = spark.read.csv(nuek_vuh3_data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRZAjZdxMYcN"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6u88hapMfPK",
    "outputId": "2f584e00-8490-4155-92ac-68cdf6095dd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---------------+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------+-------------+----------------------+-------------------+----------------------+----+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+---------------------------------+-------------+-----------------------------+-------------------+-------------------+---------------------------+\n",
      "|call_number|unit_id|incident_number|call_type       |call_date          |watch_date         |received_dttm      |entry_dttm         |dispatch_dttm      |response_dttm      |on_scene_dttm      |transport_dttm|hospital_dttm|call_final_disposition|available_dttm     |address               |city|zipcode_of_incident|battalion|station_area|box |original_priority|priority|final_priority|als_unit|call_type_group|number_of_alarms|unit_type|unit_sequence_in_call_dispatch|fire_prevention_district|supervisor_district|neighborhoods_analysis_boundaries|rowid        |case_location                |data_as_of         |data_loaded_at     |:@computed_region_ajp5_b2md|\n",
      "+-----------+-------+---------------+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------+-------------+----------------------+-------------------+----------------------+----+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+---------------------------------+-------------+-----------------------------+-------------------+-------------------+---------------------------+\n",
      "|63520271   |71     |6099527        |Medical Incident|2006-12-18 00:00:00|2006-12-18 00:00:00|2006-12-18 16:30:48|2006-12-18 16:32:45|2006-12-18 16:33:06|NULL               |NULL               |NULL          |NULL         |Other                 |NULL               |TAYLOR ST/JEFFERSON ST|SF  |94133              |B01      |28          |0945|E                |E       |3             |false   |NULL           |1               |MEDIC    |4                             |1                       |3                  |North Beach                      |063520271-71 |POINT (-122.4158 37.808212)  |2024-02-05 03:27:52|2024-02-05 10:56:25|23                         |\n",
      "|63530078   |E36    |6099669        |Alarms          |2006-12-19 00:00:00|2006-12-19 00:00:00|2006-12-19 08:39:29|2006-12-19 08:40:48|2006-12-19 08:40:54|2006-12-19 08:42:32|2006-12-19 08:44:52|NULL          |NULL         |Other                 |2006-12-19 08:56:48|LAGUNA ST/IVY ST      |SF  |94102              |B02      |36          |3413|3                |3       |3             |true    |NULL           |1               |ENGINE   |1                             |2                       |5                  |Hayes Valley                     |063530078-E36|POINT (-122.42636 37.77693)  |2024-02-05 03:27:52|2024-02-05 10:56:25|9                          |\n",
      "|63530311   |M13    |6099836        |Medical Incident|2006-12-19 00:00:00|2006-12-19 00:00:00|2006-12-19 19:49:26|2006-12-19 19:52:04|2006-12-19 19:52:22|NULL               |NULL               |NULL          |NULL         |Other                 |2006-12-19 19:54:02|AVENUE D/09TH TI ST   |TI  |94130              |B03      |48          |2931|3                |3       |3             |true    |NULL           |1               |MEDIC    |3                             |None                    |6                  |Treasure Island                  |063530311-M13|POINT (-122.37266 37.82412)  |2024-02-05 03:27:52|2024-02-05 10:56:25|37                         |\n",
      "|63540281   |T10    |6100040        |Alarms          |2006-12-20 00:00:00|2006-12-20 00:00:00|2006-12-20 16:06:01|2006-12-20 16:07:03|2006-12-20 16:07:16|NULL               |NULL               |NULL          |NULL         |Other                 |2006-12-20 16:08:35|ERKSON CT/POST ST     |SF  |94115              |B04      |10          |4131|3                |3       |3             |false   |NULL           |1               |TRUCK    |3                             |5                       |5                  |Japantown                        |063540281-T10|POINT (-122.44015 37.78426)  |2024-02-05 03:27:52|2024-02-05 10:56:25|15                         |\n",
      "|63560404   |E35    |6100734        |Alarms          |2006-12-22 00:00:00|2006-12-22 00:00:00|2006-12-22 23:14:14|2006-12-22 23:17:02|2006-12-22 23:18:08|NULL               |NULL               |NULL          |NULL         |Other                 |2006-12-22 23:20:01|STEVENSON ST/05TH ST  |SF  |94103              |B03      |1           |2212|3                |3       |3             |false   |NULL           |1               |ENGINE   |3                             |3                       |6                  |South of Market                  |063560404-E35|POINT (-122.407486 37.783527)|2024-02-05 03:27:52|2024-02-05 10:56:25|34                         |\n",
      "|63570023   |M14    |6100764        |Medical Incident|2006-12-23 00:00:00|2006-12-22 00:00:00|2006-12-23 01:13:39|2006-12-23 01:16:59|2006-12-23 01:17:21|2006-12-23 01:19:15|NULL               |NULL          |NULL         |Other                 |NULL               |48TH AVE/KIRKHAM ST   |SF  |94122              |B08      |23          |7723|1                |1       |2             |true    |NULL           |1               |MEDIC    |2                             |8                       |4                  |Sunset/Parkside                  |063570023-M14|POINT (-122.507935 37.758465)|2024-02-05 03:27:52|2024-02-05 10:56:25|35                         |\n",
      "|63600060   |M13    |6101579        |Medical Incident|2006-12-26 00:00:00|2006-12-25 00:00:00|2006-12-26 06:22:25|2006-12-26 06:24:57|2006-12-26 06:25:21|NULL               |NULL               |NULL          |NULL         |Other                 |2006-12-26 06:30:53|CALIFORNIA ST/SCOTT ST|SF  |94115              |B04      |38          |4125|3                |3       |3             |true    |NULL           |1               |MEDIC    |3                             |4                       |2                  |Pacific Heights                  |063600060-M13|POINT (-122.438774 37.788277)|2024-02-05 03:27:52|2024-02-05 10:56:25|30                         |\n",
      "|63600290   |T12    |6101737        |Medical Incident|2006-12-26 00:00:00|2006-12-26 00:00:00|2006-12-26 17:58:18|2006-12-26 18:00:20|2006-12-26 18:00:32|NULL               |NULL               |NULL          |NULL         |Other                 |NULL               |UPPER TER/MONUMENT WAY|SF  |94117              |B05      |12          |5165|3                |3       |3             |false   |NULL           |1               |TRUCK    |2                             |5                       |8                  |Haight Ashbury                   |063600290-T12|POINT (-122.44629 37.76231)  |2024-02-05 03:27:52|2024-02-05 10:56:25|3                          |\n",
      "|63610070   |T16    |6101850        |Other           |2006-12-27 00:00:00|2006-12-26 00:00:00|2006-12-27 05:38:19|2006-12-27 05:40:24|2006-12-27 05:40:36|2006-12-27 05:42:55|2006-12-27 05:45:27|NULL          |NULL         |Other                 |2006-12-27 06:08:48|LAGUNA ST/LOMBARD ST  |SF  |94123              |B04      |16          |3352|3                |3       |3             |false   |NULL           |1               |TRUCK    |1                             |4                       |2                  |Marina                           |063610070-T16|POINT (-122.431114 37.80047) |2024-02-05 03:27:52|2024-02-05 10:56:25|13                         |\n",
      "|63640354   |87     |6102991        |Medical Incident|2006-12-30 00:00:00|2006-12-30 00:00:00|2006-12-30 22:27:29|2006-12-30 22:30:01|2006-12-30 22:30:37|NULL               |NULL               |NULL          |NULL         |Other                 |2006-12-30 22:51:08|06TH ST/MINNA ST      |SF  |94103              |B03      |1           |2251|3                |3       |3             |true    |NULL           |1               |MEDIC    |3                             |3                       |6                  |South of Market                  |063640354-87 |POINT (-122.40816 37.780537) |2024-02-05 03:27:52|2024-02-05 10:56:25|34                         |\n",
      "+-----------+-------+---------------+----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+--------------+-------------+----------------------+-------------------+----------------------+----+-------------------+---------+------------+----+-----------------+--------+--------------+--------+---------------+----------------+---------+------------------------------+------------------------+-------------------+---------------------------------+-------------+-----------------------------+-------------------+-------------------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nuek_vuh3_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cQpfgHMnb3K"
   },
   "source": [
    "**Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "JYFZPbZVMoFR",
    "outputId": "951dfe24-0a8b-4708-e127-ec01d043ed71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...5\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створюємо сесію Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .appName(\"MyGoitSparkSandbox\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Завантажуємо датасет\n",
    "nuek_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(nuek_vuh3_data_path)\n",
    "\n",
    "nuek_repart = nuek_df.repartition(2)\n",
    "\n",
    "nuek_processed = nuek_repart \\\n",
    "    .where(\"final_priority < 3\") \\\n",
    "    .select(\"unit_id\", \"final_priority\") \\\n",
    "    .groupBy(\"unit_id\") \\\n",
    "    .count()\n",
    "\n",
    "# Ось ТУТ додано рядок\n",
    "nuek_processed = nuek_processed.where(\"count>2\")\n",
    "\n",
    "# nuek_processed.show()\n",
    "\n",
    "nuek_processed.collect()\n",
    "\n",
    "input(\"Press Enter to continue...5\")\n",
    "\n",
    "# Закриваємо сесію Spark\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64Fg63yTfaQk"
   },
   "source": [
    "**Отримання публічного URL до локального Spark UI на Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVUT1FlzdjsE",
    "outputId": "1d943c42-ea1e-4fc1-968b-3cd721bdbf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "# авторизаційний токен ngrock для доступу до локального Spark UI в Google Colab\n",
    "!ngrok config add-authtoken <Authtoken>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RR6WR6xlRSSD",
    "outputId": "579d1b76-37a0-4cae-9b9e-a107098f5959"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pyngrok.process.ngrok:t=2024-11-24T18:37:39+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI доступний за адресою: NgrokTunnel: \"https://1b28-34-70-241-250.ngrok-free.app\" -> \"http://localhost:4040\"\n"
     ]
    }
   ],
   "source": [
    "# Запускаємо тунель для порту 4040\n",
    "public_url = ngrok.connect(4040)\n",
    "print(f\"Spark UI доступний за адресою: {public_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XTu4Q1Zjn01f"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYsQhPNWnXI2"
   },
   "source": [
    "**Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "--fciaYjnIIr",
    "outputId": "d3f02957-904e-4fdd-b11f-1db90fc6d5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...5\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створюємо сесію Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .appName(\"MyGoitSparkSandbox\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Завантажуємо датасет\n",
    "nuek_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(nuek_vuh3_data_path)\n",
    "\n",
    "nuek_repart = nuek_df.repartition(2)\n",
    "\n",
    "nuek_processed = nuek_repart \\\n",
    "    .where(\"final_priority < 3\") \\\n",
    "    .select(\"unit_id\", \"final_priority\") \\\n",
    "    .groupBy(\"unit_id\") \\\n",
    "    .count()\n",
    "\n",
    "# Проміжний action: collect\n",
    "nuek_processed.collect()\n",
    "\n",
    "# Ось ТУТ додано рядок\n",
    "nuek_processed = nuek_processed.where(\"count>2\")\n",
    "\n",
    "nuek_processed.collect()\n",
    "\n",
    "input(\"Press Enter to continue...5\")\n",
    "\n",
    "# Закриваємо сесію Spark\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "u3a5npvLrB02"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgdHXtO1pm_4"
   },
   "source": [
    "# Чому додавання `.collect()` призвело до збільшення кількості Jobs?\n",
    "\n",
    "## Основна причина\n",
    "Spark використовує **ліниву обчислювальну модель**, де трансформації додаються в Directed Acyclic Graph (DAG) і виконуються тільки при виклику **action** (наприклад, `.collect()`). Кожен виклик `.collect()` змушує Spark виконати весь DAG до цього моменту, створюючи Jobs.\n",
    "\n",
    "---\n",
    "\n",
    "## Причина збільшення Jobs\n",
    "1. **Spark працює ліниво (lazy execution):**\n",
    "   - Трансформації (наприклад, `.where`, `.select`, `.groupBy`) лише додають операції до DAG і не виконуються негайно.\n",
    "   - Обчислення запускаються лише під час виклику **action** (наприклад, `.collect()`).\n",
    "\n",
    "2. **Два виклики `.collect()` запускають обчислення двічі:**\n",
    "   - Перший виклик `.collect()` виконує весь DAG до цього моменту.\n",
    "   - Після додаткової фільтрації (`where(\"count>2\")`) створюється новий DAG.\n",
    "   - Другий виклик `.collect()` змушує Spark виконати новий DAG.\n",
    "\n",
    "3. **Розподілення на Jobs:**\n",
    "   - Кожна складна трансформація (наприклад, `groupBy`) викликає **shuffle**, що створює нові Jobs.\n",
    "   - Кожен виклик `.collect()` викликає обчислення DAG, додаючи Jobs.\n",
    "\n",
    "---\n",
    "\n",
    "## Аналіз кількості Jobs\n",
    "\n",
    "### 1. До першого `.collect()`\n",
    "Трансформації додаються до DAG:\n",
    "- `repartition(2)` — розподіляє дані між двома партиціями.\n",
    "- `where(\"final_priority < 3\")` — фільтрує рядки.\n",
    "- `select` — вибирає потрібні стовпці.\n",
    "- `groupBy(\"unit_id\").count()` — групує дані, викликаючи **shuffle**.\n",
    "\n",
    "Коли викликається перше `.collect()`, Spark:\n",
    "- Виконує весь DAG, створюючи кілька Jobs.\n",
    "\n",
    "### 2. Додаткове фільтрування та друге `.collect()`\n",
    "- Фільтрація (`where(\"count>2\")`) створює новий DAG.\n",
    "- Друге `.collect()` викликає обчислення нового DAG, створюючи ще кілька Jobs.\n",
    "\n",
    "---\n",
    "\n",
    "## Чому саме 3 додаткові Jobs?\n",
    "1. Перше `.collect()` запускає Jobs для обчислення всього попереднього DAG.\n",
    "2. Додане фільтрування створює новий DAG.\n",
    "3. Друге `.collect()` запускає Jobs для нового DAG.\n",
    "4. Spark не використовує кешування між викликами `.collect()` (якщо не вказати це явно), тому всі операції виконуються повторно.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAExpJPVrF_d"
   },
   "source": [
    "**Task 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDznjnxOrIby",
    "outputId": "fe7bc369-95e2-49b9-bd71-05f7a5e01099"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[unit_id: string, count: bigint]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Створюємо сесію Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "    .appName(\"MyGoitSparkSandbox\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Завантажуємо датасет\n",
    "nuek_df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(nuek_vuh3_data_path)\n",
    "\n",
    "nuek_repart = nuek_df.repartition(2)\n",
    "\n",
    "nuek_processed_cached = nuek_repart \\\n",
    "    .where(\"final_priority < 3\") \\\n",
    "    .select(\"unit_id\", \"final_priority\") \\\n",
    "    .groupBy(\"unit_id\") \\\n",
    "    .count() \\\n",
    "    .cache()  # Додано функцію cache\n",
    "\n",
    "# Проміжний action: collect\n",
    "nuek_processed_cached.collect()\n",
    "\n",
    "# Ось ТУТ додано рядок\n",
    "nuek_processed = nuek_processed_cached.where(\"count>2\")\n",
    "\n",
    "nuek_processed.collect()\n",
    "\n",
    "input(\"Press Enter to continue...5\")\n",
    "\n",
    "# Звільняємо пям'ять від Dataframe\n",
    "nuek_processed_cached.unpersist()\n",
    "\n",
    "# Закриваємо сесію Spark\n",
    "# spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "R9cPvV5gsOQO"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-WFLDktsHWX"
   },
   "source": [
    "# Зменшення кількості Jobs\n",
    "\n",
    "## Без кешування:\n",
    "- Кожен виклик `.collect()` змушує Spark виконати всі трансформації з самого початку.\n",
    "- Це призводить до повторного виконання DAG і додаткових Jobs.\n",
    "\n",
    "## З кешуванням:\n",
    "- При першому виконанні Spark обчислює весь DAG і кешує результат.\n",
    "- Усі подальші виклики **action** використовують кешовані дані, зменшуючи обсяг роботи та кількість Jobs.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
